# export_assets_local.py
# ä½œç”¨ï¼š1. ç°åœºè®­ç»ƒ LCA æå–å‚æ•°; 2. æ¬è¿ TabPFN æ¨¡å‹
# è¿è¡Œæ–¹å¼ï¼šåŒå‡»è¿è¡Œï¼Œæˆ–è€…åœ¨ç»ˆç«¯ python export_assets_local.py

import os
import shutil
import pandas as pd
import numpy as np
import joblib
import json

# ================= ğŸ”´ è¯·æ ¸å¯¹ä½ çš„ E ç›˜è·¯å¾„ ğŸ”´ =================
# ä½ çš„é¡¹ç›®æ ¹ç›®å½•
YOUR_PROJECT_ROOT = r"E:\code_piantoutong"

# åŸå§‹æ•°æ®è·¯å¾„ (ç”¨äºç°åœºè·‘ LCA)
RAW_DATA_PATH = os.path.join(YOUR_PROJECT_ROOT, "processed_migraine_event_level_allv3.xlsx")
SHEET_NAME = "äº‹ä»¶çº§_åˆå¹¶æ•°æ®"

# TabPFN æ¨¡å‹ç›®å½•
TABPFN_DIR = os.path.join(YOUR_PROJECT_ROOT, "WeakSupervision_TabPFN")
TABPFN_48H_DIR = os.path.join(YOUR_PROJECT_ROOT, "WeakSupervision_TabPFN_48hOnly")
CKPT_PATH = os.path.join(YOUR_PROJECT_ROOT, r"TabPFN_score\tabpfn-v2.5-regressor-v2.5_default.ckpt")

# LCA é…ç½® (è·Ÿä½ åŸè„šæœ¬ä¿æŒä¸€è‡´)
N_CLASSES_LCA = 6  # ä½ ä¹‹å‰çš„ç»“è®ºæ˜¯ K=6 æœ€ä¼˜
MAX_ITER = 300
TOL = 1e-4
ALPHA_SMOOTH = 1.0
RANDOM_STATE = 2025
# ===================================================================

# ç›®æ ‡è¾“å‡ºç›®å½• (è‡ªåŠ¨åˆ›å»ºåœ¨å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„ models)
DEST_DIR = os.path.join(os.path.dirname(__file__), "models")
os.makedirs(DEST_DIR, exist_ok=True)


# --- æŠŠä½ çš„ LCA æ ¸å¿ƒç®—æ³•æ¬è¿‡æ¥ ---
def lca_em(X, n_classes, max_iter=300, tol=1e-4, random_state=None, alpha_smooth=1.0):
    rng = np.random.RandomState(random_state)
    N, D = X.shape
    pi = np.ones(n_classes) / n_classes
    theta = rng.uniform(0.25, 0.75, size=(n_classes, D))
    X1 = X
    X0 = 1 - X1
    prev_ll = None

    for it in range(max_iter):
        # E-step
        log_theta = np.log(theta + 1e-12)
        log_1_minus_theta = np.log(1 - theta + 1e-12)
        log_px_given_k = (X1[:, None, :] * log_theta[None, :, :] + X0[:, None, :] * log_1_minus_theta[None, :, :]).sum(
            axis=2)
        log_pi = np.log(pi + 1e-12)
        log_joint = log_px_given_k + log_pi[None, :]
        max_log = np.max(log_joint, axis=1, keepdims=True)
        log_sum_exp = max_log + np.log(np.sum(np.exp(log_joint - max_log), axis=1, keepdims=True) + 1e-12)
        log_gamma = log_joint - log_sum_exp
        gamma = np.exp(log_gamma)
        ll = log_sum_exp.sum()
        if prev_ll is not None and np.abs(ll - prev_ll) < tol: break
        prev_ll = ll

        # M-step
        Nk = gamma.sum(axis=0)
        pi = Nk / N
        theta = (gamma.T @ X1 + alpha_smooth) / (Nk[:, None] + 2 * alpha_smooth)

    return pi, theta


def train_and_export_lca():
    print(f"1. æ­£åœ¨è¯»å–åŸå§‹æ•°æ®: {RAW_DATA_PATH} ...")
    if not os.path.exists(RAW_DATA_PATH):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åŸå§‹æ•°æ®: {RAW_DATA_PATH}")

    df = pd.read_excel(RAW_DATA_PATH, sheet_name=SHEET_NAME)

    # è¿‡æ»¤æ— æ•ˆæ•°æ®
    if "æœ¬æ¬¡48hç—‡çŠ¶æ˜¯å¦å…¨éƒ¨ç¼ºå¤±" in df.columns:
        df = df[~(df["æœ¬æ¬¡48hç—‡çŠ¶æ˜¯å¦å…¨éƒ¨ç¼ºå¤±"] == True)].copy()

    # æå–ç—‡çŠ¶åˆ—
    symptom_cols = [c for c in df.columns if c.endswith("_48h")]
    print(f"   æå–åˆ° {len(symptom_cols)} ä¸ªç—‡çŠ¶ç‰¹å¾ï¼Œæ­£åœ¨è¿›è¡Œ LCA è®­ç»ƒ (K={N_CLASSES_LCA})...")

    X = df[symptom_cols].fillna(0).values.astype(int)

    # ç°åœºè®­ç»ƒ
    pi, theta = lca_em(X, n_classes=N_CLASSES_LCA, max_iter=MAX_ITER, tol=TOL, random_state=RANDOM_STATE,
                       alpha_smooth=ALPHA_SMOOTH)

    # ä¿å­˜å‚æ•°
    lca_assets = {
        "pi": pi,
        "theta": theta,
        "symptom_cols": symptom_cols,
        "n_classes": N_CLASSES_LCA
    }

    save_path = os.path.join(DEST_DIR, "lca_params.pkl")
    joblib.dump(lca_assets, save_path)
    print(f"âœ… LCA è®­ç»ƒå®Œæˆï¼Œå‚æ•°å·²ä¿å­˜è‡³: {save_path}")


def copy_models():
    print("2. æ­£åœ¨å¤åˆ¶ TabPFN æ¨¡å‹æ–‡ä»¶...")

    files_to_copy = [
        (os.path.join(TABPFN_DIR, "models", "tabpfn.pkl"), "tabpfn_longterm.pkl"),
        (os.path.join(TABPFN_48H_DIR, "models", "tabpfn_48h_only.pkl"), "tabpfn_48h_only.pkl"),
        (os.path.join(TABPFN_DIR, "models", "feat_cols.json"), "feat_cols_longterm.json"),
        (os.path.join(TABPFN_48H_DIR, "models", "feat_cols_48h_only.json"), "feat_cols_48h.json"),
        (CKPT_PATH, "tabpfn-v2.5-regressor-v2.5_default.ckpt")
    ]

    for src, dst_name in files_to_copy:
        if os.path.exists(src):
            shutil.copy(src, os.path.join(DEST_DIR, dst_name))
            print(f"âœ… å·²å¤åˆ¶: {dst_name}")
        else:
            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡: {src}")


def main():
    try:
        train_and_export_lca()
        copy_models()
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰èµ„äº§å·²å‡†å¤‡å°±ç»ªã€‚")
        print("ç°åœ¨ä½ å¯ä»¥è¿è¡Œå¯åŠ¨è„šæœ¬äº†ã€‚")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        input("æŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()
